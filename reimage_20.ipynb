{"cells":[{"cell_type":"code","execution_count":18,"id":"xDsndgKXZ_DJ","metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1698583031796,"user":{"displayName":"yf Wang","userId":"11168396825643978001"},"user_tz":-480},"id":"xDsndgKXZ_DJ"},"outputs":[],"source":["import os\n","os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""]},{"cell_type":"code","execution_count":19,"id":"1P46Snv1HFKz","metadata":{"executionInfo":{"elapsed":4496,"status":"ok","timestamp":1698583036290,"user":{"displayName":"yf Wang","userId":"11168396825643978001"},"user_tz":-480},"id":"1P46Snv1HFKz"},"outputs":[],"source":["import torch\n","device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":20,"id":"Nl9So_6ZHKlL","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1698583036291,"user":{"displayName":"yf Wang","userId":"11168396825643978001"},"user_tz":-480},"id":"Nl9So_6ZHKlL","outputId":"94848f71-1e30-4cfc-a703-d68e09e15a55"},"outputs":[{"data":{"text/plain":["device(type='cuda')"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["device"]},{"attachments":{},"cell_type":"markdown","id":"1cd3e30f","metadata":{"id":"1cd3e30f"},"source":["## Net construction"]},{"cell_type":"code","execution_count":21,"id":"21296042","metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1698583036291,"user":{"displayName":"yf Wang","userId":"11168396825643978001"},"user_tz":-480},"id":"21296042"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torchvision\n","import torchvision.transforms as transforms\n","\n","#batch_size=\n","#num_classes=\n","#learning_rate=\n","#num_epochs=\n","strides=[1,3,3]\n","vertical_dilation=[1,2,3]\n","blocks=[2,3,4]\n","num_filters=64\n","device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","use_gpu = torch.cuda.is_available()"]},{"cell_type":"code","execution_count":22,"id":"14f1fb4f","metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1698583036291,"user":{"displayName":"yf Wang","userId":"11168396825643978001"},"user_tz":-480},"id":"14f1fb4f"},"outputs":[],"source":["# only for mac\n","# device=torch.device('mps')"]},{"cell_type":"code","execution_count":23,"id":"bc861962","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1698583036291,"user":{"displayName":"yf Wang","userId":"11168396825643978001"},"user_tz":-480},"id":"bc861962","outputId":"96f402b6-17ee-4b86-f14d-c6f4209bd9a8"},"outputs":[],"source":["class Day_20cnn(nn.Module):\n","    def __init__(self):\n","        super(Day_20cnn, self).__init__()\n","        self.conv1 = nn.Sequential(nn.Conv2d(in_channels=1,out_channels=64,kernel_size=(5,3),padding=(7,1),stride=(3,1),dilation=(2,1)),\n","                                  nn.BatchNorm2d(64), # Accelerating Deep Network Training by Reducing Internal Covariate Shift, normliaze data/features\n","                                  nn.LeakyReLU(),\n","                                  nn.MaxPool2d(kernel_size=(2,1))\n","                                  )\n","        self.conv2 = nn.Sequential(nn.Conv2d(in_channels=64,out_channels=128,kernel_size=(5,3),padding=(2,1),stride=1),\n","                                  nn.BatchNorm2d(128),\n","                                  nn.LeakyReLU(),\n","                                  nn.MaxPool2d(kernel_size=(2,1))\n","                                  )\n","        self.conv3 = nn.Sequential(nn.Conv2d(in_channels=128,out_channels=256,kernel_size=(5,3),padding=(2,1),stride=1),\n","                                  nn.BatchNorm2d(256),\n","                                  nn.LeakyReLU(),\n","                                  nn.MaxPool2d(kernel_size=(2,1))\n","                                  )\n","        self.fc1 = nn.Sequential(nn.Dropout(p=0.5),\n","                                 nn.Linear(46080,2))\n","        \n","    def forward(self,x):\n","        y = self.conv1(x)\n","        y = self.conv2(y)\n","        y = self.conv3(y)\n","        y = y.view(y.shape[0],-1)\n","        y = self.fc1(y)\n","        # y=self.sfm(y)\n","        return y"]},{"cell_type":"code","execution_count":24,"id":"4c4faaa3","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12238,"status":"ok","timestamp":1698583048521,"user":{"displayName":"yf Wang","userId":"11168396825643978001"},"user_tz":-480},"id":"4c4faaa3","outputId":"daac74cd-c826-4158-d9ea-3564fdedb990"},"outputs":[{"name":"stdout","output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 64, 24, 60]           1,024\n","       BatchNorm2d-2           [-1, 64, 24, 60]             128\n","         LeakyReLU-3           [-1, 64, 24, 60]               0\n","         MaxPool2d-4           [-1, 64, 12, 60]               0\n","            Conv2d-5          [-1, 128, 12, 60]         123,008\n","       BatchNorm2d-6          [-1, 128, 12, 60]             256\n","         LeakyReLU-7          [-1, 128, 12, 60]               0\n","         MaxPool2d-8           [-1, 128, 6, 60]               0\n","            Conv2d-9           [-1, 256, 6, 60]         491,776\n","      BatchNorm2d-10           [-1, 256, 6, 60]             512\n","        LeakyReLU-11           [-1, 256, 6, 60]               0\n","        MaxPool2d-12           [-1, 256, 3, 60]               0\n","          Dropout-13                [-1, 46080]               0\n","           Linear-14                    [-1, 2]          92,162\n","================================================================\n","Total params: 708,866\n","Trainable params: 708,866\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.01\n","Forward/backward pass size (MB): 7.73\n","Params size (MB): 2.70\n","Estimated Total Size (MB): 10.45\n","----------------------------------------------------------------\n"]}],"source":["net_day20=Day_20cnn()\n","# device_ids = [0, 1]\n","# net_day20 = torch.nn.DataParallel(net_day20, device_ids=device_ids)\n","net_day20.cuda()\n","from torchsummary import summary\n","# import os\n","# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n","\n","#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n","#use_gpu = torch.cuda.is_available()\n","#device = torch.device(\"cuda\" if use_gpu else \"cpu\")\n","#print(device)\n","\n","summary(net_day20, input_size=(1,64,60))"]},{"attachments":{},"cell_type":"markdown","id":"beaa6387","metadata":{"id":"beaa6387"},"source":["## Date load"]},{"cell_type":"code","execution_count":25,"id":"51acb4d5","metadata":{"executionInfo":{"elapsed":470,"status":"ok","timestamp":1698583048984,"user":{"displayName":"yf Wang","userId":"11168396825643978001"},"user_tz":-480},"id":"51acb4d5"},"outputs":[],"source":["import torchvision\n","import os\n","import pandas as pd\n","import numpy as np\n","IMAGE_WIDTH={5:15, 20:60, 60:180}\n","IMAGE_HEIGHT={5:32, 20:64, 60:96}\n","\n","def data_set(dir, year_index, in_size, out_size):\n","    year = year_index[0]\n","    img_path = os.path.join(dir,\"monthly_20d\",f\"20d_month_has_vb_[20]_ma_{year}_images.dat\")\n","    label_path = os.path.join(dir,\"monthly_20d\",f\"20d_month_has_vb_[20]_ma_{year}_labels_w_delay.feather\")\n","    image = np.memmap(img_path,dtype=np.uint8,mode='r').reshape(-1,IMAGE_HEIGHT[in_size],IMAGE_WIDTH[out_size])\n","    label = pd.read_feather(label_path)\n","\n","    for year in year_index[1:]:\n","        img_path = os.path.join(dir,\"monthly_20d\",f\"20d_month_has_vb_[20]_ma_{year}_images.dat\")\n","        label_path = os.path.join(dir,\"monthly_20d\",f\"20d_month_has_vb_[20]_ma_{year}_labels_w_delay.feather\")\n","        img = np.memmap(img_path,dtype=np.uint8,mode='r').reshape(-1,IMAGE_HEIGHT[in_size],IMAGE_WIDTH[out_size])\n","        lbl = pd.read_feather(label_path)\n","        image = np.concatenate((image,img),axis=0)\n","        label = pd.concat([label,lbl])\n","    return image, label\n","\n","def sampling(image, label):\n","    len_df = len(label)\n","    random_index = np.random.permutation(len_df)\n","    train_index = random_index[:int(0.7*len_df)]\n","    train_image = image[train_index]\n","    # print(label.index)\n","    # print(train_index)\n","    train_label = label.iloc[train_index,:]\n","    validation_index = random_index[int(0.7*len_df):]\n","    validation_image = image[validation_index]\n","    validation_label = label.iloc[validation_index,:]\n","    return train_image, train_label, validation_image,validation_label"]},{"cell_type":"code","execution_count":26,"id":"8104ecf8","metadata":{"executionInfo":{"elapsed":41646,"status":"ok","timestamp":1698583090627,"user":{"displayName":"yf Wang","userId":"11168396825643978001"},"user_tz":-480},"id":"8104ecf8"},"outputs":[],"source":["# we train and validate each model only once using data from 1993 to 2000, in\n","# which 70% of the sample are randomly selected for training and the remaining 30% for validation.\n","# train - validation\n","# img_dir = \"/Users/evan_wang/Library/CloudStorage/OneDrive-Microsoft/code/python/pytorch/data\"\n","img_dir = \"/home/ywangtb/ai_fintech\"\n","train_index = np.arange(1993, 2001, 1)\n","# train = True\n","in_size = 20\n","out_size = 20\n","image, label = data_set(img_dir, train_index, in_size, out_size)\n","train_image, train_label, validation_image,validation_label = sampling(image, label)"]},{"cell_type":"code","execution_count":27,"id":"e19b12da","metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1698583090627,"user":{"displayName":"yf Wang","userId":"11168396825643978001"},"user_tz":-480},"id":"e19b12da"},"outputs":[],"source":["# test\n","test_index = np.arange(2001, 2002, 1)\n","train = False\n","in_size = 20\n","out_size = 20\n","test_image, test_label = data_set(img_dir, test_index, in_size, out_size)"]},{"cell_type":"code","execution_count":28,"id":"58030513","metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1698583090627,"user":{"displayName":"yf Wang","userId":"11168396825643978001"},"user_tz":-480},"id":"58030513"},"outputs":[],"source":["class Stock(torch.utils.data.Dataset):\n","    def __init__(self, image, label,transform):\n","        self.image = image\n","        self.label = label\n","        self.transform = transform\n","        self.pre_process()\n","    def __len__(self):\n","        return len(self.label)\n","    def __getitem__(self, index):\n","        image = self.transform(self.image[index])\n","        return image, self.label.iloc[index, -1]\n","    def pre_process(self):\n","        self.label['Label_20d'] = self.label['Ret_20d']\n","        # self.label['Label_20d'] = self.label['Ret_5d']\n","        self.label.loc[self.label['Label_20d']<=0, 'Label_20d']=0\n","        self.label.loc[self.label['Label_20d']>0, 'Label_20d']=1\n","        self.label.loc[pd.isnull(self.label['Label_20d']), 'Label_20d']=0\n"]},{"cell_type":"code","execution_count":29,"id":"449ef840","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1698583090627,"user":{"displayName":"yf Wang","userId":"11168396825643978001"},"user_tz":-480},"id":"449ef840","outputId":"e55be2ee-b3ef-4669-ad74-e5141869e046"},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_586460/3141858913.py:13: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  self.label['Label_20d'] = self.label['Ret_20d']\n","/tmp/ipykernel_586460/3141858913.py:13: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  self.label['Label_20d'] = self.label['Ret_20d']\n"]}],"source":["mytransform = torchvision.transforms.ToTensor()\n","train_data = Stock(train_image, train_label, mytransform)\n","validation_data = Stock(validation_image, validation_label, mytransform)\n","test_data = Stock(test_image, test_label, mytransform)"]},{"cell_type":"code","execution_count":30,"id":"0d0ba7b5","metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1698583090627,"user":{"displayName":"yf Wang","userId":"11168396825643978001"},"user_tz":-480},"id":"0d0ba7b5"},"outputs":[],"source":["train_loader=torch.utils.data.DataLoader(dataset=train_data, batch_size=128,shuffle=True,num_workers=2)\n","validation_loader=torch.utils.data.DataLoader(dataset=validation_data, batch_size=128,shuffle=True,num_workers=2)\n","test_loader=torch.utils.data.DataLoader(dataset=test_data, batch_size=128,shuffle=True,num_workers=2)\n","# loaders = {'train': train_loader, 'validation': validation_loader}\n","loaders = {'train': train_loader, 'validation': validation_loader, 'test': test_loader}"]},{"cell_type":"code","execution_count":31,"id":"bdaddf20","metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1698583090628,"user":{"displayName":"yf Wang","userId":"11168396825643978001"},"user_tz":-480},"id":"bdaddf20"},"outputs":[],"source":["# examples = enumerate(data_loader)\n","# batch_idx, (example_data, example_targets) = next(examples)"]},{"attachments":{},"cell_type":"markdown","id":"ac25a60e","metadata":{"id":"ac25a60e"},"source":[]},{"cell_type":"code","execution_count":32,"id":"44ef52a0","metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1698583090628,"user":{"displayName":"yf Wang","userId":"11168396825643978001"},"user_tz":-480},"id":"44ef52a0"},"outputs":[],"source":["# import matplotlib.pyplot as plt\n","# plt.imshow(example_data[0].numpy(), cmap='gray')"]},{"attachments":{},"cell_type":"markdown","id":"1fd2c2b6","metadata":{"id":"1fd2c2b6"},"source":["# Train the model"]},{"cell_type":"code","execution_count":33,"id":"d3bb2d76","metadata":{"executionInfo":{"elapsed":914,"status":"ok","timestamp":1698583091534,"user":{"displayName":"yf Wang","userId":"11168396825643978001"},"user_tz":-480},"id":"d3bb2d76"},"outputs":[],"source":["import os\n","import re\n","import time\n","\n","\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","def accuracy(output, target, topk=1):\n","    batch_size = target.size(0)\n","    _, pred = output.topk(topk, 1, True, True)\n","    pred = pred.t()\n","    correct = pred.eq(target.view(1, -1).expand_as(pred))\n","\n","    res = []\n","    res.append(correct.sum()/batch_size*100)\n","    # print(res)\n","    return res\n","\n","def train_model(model, criterion, optimizer, log_saver):\n","\n","    def init_weights(m):\n","        if type(m) == nn.Linear or type(m) == nn.Conv2d:\n","            nn.init.xavier_uniform_(m.weight)\n","    model = model.cuda()\n","    model.apply(init_weights)\n","\n","    since = time.time()\n","    steps = 0\n","    epoch = 1\n","    stopping = 0\n","    iter = 0\n","    # we use early stopping to halt training once the\n","    # validation sample loss function fails to improve for two consecutive epochs.\n","    while(stopping < 2):\n","    # while(iter == 0):\n","        iter += 1\n","        \n","        print('Epoch {}'.format(epoch))\n","        print('-' * 30)\n","        for phase in ['train', 'validation']: # may need consider validation to tune parameter\n","\n","            loss_meter = AverageMeter()\n","            acc_meter = AverageMeter()\n","            # margin_error_meter = AverageMeter()\n","\n","            if phase == 'train':\n","                print('train','-' * 24)\n","                model.train(True)\n","            else:\n","                print('validation','-' * 19)\n","                model.train(False)\n","\n","            current = 0\n","\n","            for i, data in enumerate(loaders[re.findall('[a-zA-Z]+',\n","                                                        phase)[0]]):\n","                inputs, labels = data\n","                if use_gpu:\n","                    inputs = inputs.cuda()\n","                    labels = labels.cuda()\n","\n","                optimizer.zero_grad()\n","\n","                outputs = model(inputs)\n","                _, preds = torch.max(outputs.data, 1)\n","                # print(labels)\n","                labels = labels.long()\n","\n","                # print(labels)\n","                loss = criterion(outputs, labels)\n","\n","                if phase == 'train':\n","                    loss.backward()\n","                    optimizer.step()\n","                    steps += 1\n","\n","                N = outputs.size(0)\n","                # print(N)\n","                loss_meter.update(loss.data.item(), N)\n","                acc_meter.update(\n","                    accuracy(outputs.data, labels.data)[-1].item(), N)\n","                # if phase == 'train':\n","                current += len(inputs)\n","                if i % 500 == 499:\n","                    print(f\"batch: {i+1} loss: {loss_meter.avg:>7f}  [{current:>5d}/{len(loaders[re.findall('[a-zA-Z]+',phase)[0]].dataset):>5d}]\")\n","\n","            epoch_loss = loss_meter.avg\n","            epoch_error = 1 - acc_meter.avg / 100\n","\n","            if phase == 'train':\n","                log_saver['train_loss'].append(epoch_loss)\n","                log_saver['train_error'].append(epoch_error)\n","\n","            elif phase == 'validation':\n","\n","                log_saver['test_loss'].append(epoch_loss)\n","                log_saver['test_error'].append(epoch_error)\n","\n","                if iter > 2 and (log_saver['test_loss'][-1] >= log_saver['test_loss'][-2]):\n","                    stopping += 1\n","                else:\n","                    stopping = 0\n","\n","            print(\n","                f'-- {phase} loss: {epoch_loss:.4f}; error: {epoch_error:.4f}'\n","            )\n","\n","        epoch += 1\n","\n","        # if epoch % 10 == 0:\n","    print('Saving..')\n","    torch.save(model,'save.pt')\n","\n","\n","    time_elapsed = time.time() - since\n","    print(\n","        f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s'\n","    )\n","    # print(\"Now print the test outcome\")\n","    # phase = \"test\"\n","    # inputs, labels = loaders[phase]\n","    # if use_gpu:\n","    # # inputs = inputs.to(device)\n","    # # labels = labels.to(device)\n","    #     inputs = inputs.cuda()\n","    #     labels = labels.cuda()\n","\n","    # optimizer.zero_grad()\n","\n","    # outputs = model(inputs)\n","    # _, preds = torch.max(outputs.data, 1)\n","    # labels = labels.long()\n","    # loss = criterion(outputs, labels)\n","\n","    # epoch_loss = loss.data.item()\n","    # epoch_error = 1 - accuracy(outputs.data, labels.data)[-1].item() / 100\n","    # print(f'{phase} loss: {epoch_loss:.4f}; error: {epoch_error:.4f}')\n","\n","    return model, log_saver\n"]},{"cell_type":"code","execution_count":34,"id":"ea08f457","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":408549,"status":"ok","timestamp":1698583500076,"user":{"displayName":"yf Wang","userId":"11168396825643978001"},"user_tz":-480},"id":"ea08f457","outputId":"d32c6a85-2961-4f5c-f004-0ba39a4d9e78"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1\n","------------------------------\n","train ------------------------\n","batch: 500 loss: 1.030984  [64000/555113]\n","batch: 1000 loss: 0.949619  [128000/555113]\n","batch: 1500 loss: 0.896092  [192000/555113]\n","batch: 2000 loss: 0.864153  [256000/555113]\n","batch: 2500 loss: 0.839929  [320000/555113]\n","batch: 3000 loss: 0.823541  [384000/555113]\n","batch: 3500 loss: 0.810108  [448000/555113]\n","batch: 4000 loss: 0.798978  [512000/555113]\n","-- train loss: 0.7931; error: 0.4921\n","validation -------------------\n","batch: 500 loss: 0.722041  [64000/237906]\n","batch: 1000 loss: 0.721535  [128000/237906]\n","batch: 1500 loss: 0.721959  [192000/237906]\n","-- validation loss: 0.7220; error: 0.5063\n","Epoch 2\n","------------------------------\n","train ------------------------\n","batch: 500 loss: 0.713485  [64000/555113]\n","batch: 1000 loss: 0.712225  [128000/555113]\n","batch: 1500 loss: 0.710884  [192000/555113]\n","batch: 2000 loss: 0.710420  [256000/555113]\n","batch: 2500 loss: 0.709255  [320000/555113]\n","batch: 3000 loss: 0.708374  [384000/555113]\n","batch: 3500 loss: 0.707630  [448000/555113]\n","batch: 4000 loss: 0.706801  [512000/555113]\n","-- train loss: 0.7064; error: 0.4824\n","validation -------------------\n","batch: 500 loss: 0.690213  [64000/237906]\n","batch: 1000 loss: 0.690502  [128000/237906]\n","batch: 1500 loss: 0.690591  [192000/237906]\n","-- validation loss: 0.6908; error: 0.4693\n","Epoch 3\n","------------------------------\n","train ------------------------\n","batch: 500 loss: 0.697706  [64000/555113]\n","batch: 1000 loss: 0.697783  [128000/555113]\n","batch: 1500 loss: 0.697265  [192000/555113]\n","batch: 2000 loss: 0.697111  [256000/555113]\n","batch: 2500 loss: 0.696719  [320000/555113]\n","batch: 3000 loss: 0.696316  [384000/555113]\n","batch: 3500 loss: 0.696019  [448000/555113]\n","batch: 4000 loss: 0.695545  [512000/555113]\n","-- train loss: 0.6953; error: 0.4703\n","validation -------------------\n","batch: 500 loss: 0.689301  [64000/237906]\n","batch: 1000 loss: 0.689189  [128000/237906]\n","batch: 1500 loss: 0.689559  [192000/237906]\n","-- validation loss: 0.6898; error: 0.4646\n","Epoch 4\n","------------------------------\n","train ------------------------\n","batch: 500 loss: 0.690898  [64000/555113]\n","batch: 1000 loss: 0.690684  [128000/555113]\n","batch: 1500 loss: 0.690471  [192000/555113]\n","batch: 2000 loss: 0.690353  [256000/555113]\n","batch: 2500 loss: 0.690253  [320000/555113]\n","batch: 3000 loss: 0.690117  [384000/555113]\n","batch: 3500 loss: 0.689979  [448000/555113]\n","batch: 4000 loss: 0.689885  [512000/555113]\n","-- train loss: 0.6897; error: 0.4609\n","validation -------------------\n","batch: 500 loss: 0.688103  [64000/237906]\n","batch: 1000 loss: 0.688985  [128000/237906]\n","batch: 1500 loss: 0.688587  [192000/237906]\n","-- validation loss: 0.6886; error: 0.4589\n","Epoch 5\n","------------------------------\n","train ------------------------\n","batch: 500 loss: 0.686242  [64000/555113]\n","batch: 1000 loss: 0.686938  [128000/555113]\n","batch: 1500 loss: 0.686828  [192000/555113]\n","batch: 2000 loss: 0.686635  [256000/555113]\n","batch: 2500 loss: 0.686420  [320000/555113]\n","batch: 3000 loss: 0.686523  [384000/555113]\n","batch: 3500 loss: 0.686622  [448000/555113]\n","batch: 4000 loss: 0.686596  [512000/555113]\n","-- train loss: 0.6865; error: 0.4530\n","validation -------------------\n","batch: 500 loss: 0.687866  [64000/237906]\n","batch: 1000 loss: 0.687980  [128000/237906]\n","batch: 1500 loss: 0.688059  [192000/237906]\n","-- validation loss: 0.6881; error: 0.4576\n","Epoch 6\n","------------------------------\n","train ------------------------\n","batch: 500 loss: 0.684797  [64000/555113]\n","batch: 1000 loss: 0.685841  [128000/555113]\n","batch: 1500 loss: 0.685246  [192000/555113]\n","batch: 2000 loss: 0.685235  [256000/555113]\n","batch: 2500 loss: 0.685222  [320000/555113]\n","batch: 3000 loss: 0.685099  [384000/555113]\n","batch: 3500 loss: 0.685120  [448000/555113]\n","batch: 4000 loss: 0.685037  [512000/555113]\n","-- train loss: 0.6850; error: 0.4496\n","validation -------------------\n","batch: 500 loss: 0.685404  [64000/237906]\n","batch: 1000 loss: 0.685452  [128000/237906]\n","batch: 1500 loss: 0.685465  [192000/237906]\n","-- validation loss: 0.6855; error: 0.4535\n","Epoch 7\n","------------------------------\n","train ------------------------\n","batch: 500 loss: 0.681983  [64000/555113]\n","batch: 1000 loss: 0.682331  [128000/555113]\n","batch: 1500 loss: 0.682545  [192000/555113]\n","batch: 2000 loss: 0.682827  [256000/555113]\n","batch: 2500 loss: 0.682986  [320000/555113]\n","batch: 3000 loss: 0.683080  [384000/555113]\n","batch: 3500 loss: 0.683139  [448000/555113]\n","batch: 4000 loss: 0.683224  [512000/555113]\n","-- train loss: 0.6833; error: 0.4440\n","validation -------------------\n","batch: 500 loss: 0.685473  [64000/237906]\n","batch: 1000 loss: 0.685399  [128000/237906]\n","batch: 1500 loss: 0.685186  [192000/237906]\n","-- validation loss: 0.6850; error: 0.4518\n","Epoch 8\n","------------------------------\n","train ------------------------\n","batch: 500 loss: 0.680884  [64000/555113]\n","batch: 1000 loss: 0.680815  [128000/555113]\n","batch: 1500 loss: 0.681426  [192000/555113]\n","batch: 2000 loss: 0.681259  [256000/555113]\n","batch: 2500 loss: 0.681221  [320000/555113]\n","batch: 3000 loss: 0.681214  [384000/555113]\n","batch: 3500 loss: 0.681389  [448000/555113]\n","batch: 4000 loss: 0.681390  [512000/555113]\n","-- train loss: 0.6815; error: 0.4394\n","validation -------------------\n","batch: 500 loss: 0.685033  [64000/237906]\n","batch: 1000 loss: 0.685211  [128000/237906]\n","batch: 1500 loss: 0.685230  [192000/237906]\n","-- validation loss: 0.6853; error: 0.4513\n","Epoch 9\n","------------------------------\n","train ------------------------\n","batch: 500 loss: 0.678154  [64000/555113]\n","batch: 1000 loss: 0.678863  [128000/555113]\n","batch: 1500 loss: 0.678643  [192000/555113]\n","batch: 2000 loss: 0.678800  [256000/555113]\n","batch: 2500 loss: 0.679088  [320000/555113]\n","batch: 3000 loss: 0.679258  [384000/555113]\n","batch: 3500 loss: 0.679475  [448000/555113]\n","batch: 4000 loss: 0.679570  [512000/555113]\n","-- train loss: 0.6796; error: 0.4342\n","validation -------------------\n","batch: 500 loss: 0.687521  [64000/237906]\n","batch: 1000 loss: 0.687339  [128000/237906]\n","batch: 1500 loss: 0.687075  [192000/237906]\n","-- validation loss: 0.6868; error: 0.4536\n","Saving..\n","Training complete in 16m 21s\n"]}],"source":["import torch.optim as optim\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(net_day20.parameters(), lr=0.0001,betas = (0.9,0.99))\n","# optimizer = optim.SGD(net_day20.parameters(), lr=0.00001, momentum=0.9) # use adam\n","# device_ids = [0, 1]\n","# optimizer = nn.DataParallel(optimizer, device_ids=device_ids)\n","# The log for recording train (test) loss and errors.\n","log = {\n","    # 'num_params': [],\n","    'train_loss': [],\n","    'train_error': [],\n","    'test_loss': [],\n","    'test_error': []\n","}\n","model, log = train_model(\n","    net_day20, criterion, optimizer, log)"]},{"cell_type":"code","execution_count":55,"id":"74341776","metadata":{},"outputs":[],"source":["x = torch.from_numpy(test_image[:]/255).reshape(len(test_image),1,64,60).cuda().float()\n"]},{"cell_type":"code","execution_count":null,"id":"2VQJQgPOxGYS","metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1698583500076,"user":{"displayName":"yf Wang","userId":"11168396825643978001"},"user_tz":-480},"id":"2VQJQgPOxGYS"},"outputs":[],"source":["# log_pd = pd.DataFrame(log)\n","# log_pd.to_csv('log_pd.csv')"]},{"cell_type":"code","execution_count":null,"id":"CgDNXLORpITP","metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1698583513293,"user":{"displayName":"yf Wang","userId":"11168396825643978001"},"user_tz":-480},"id":"CgDNXLORpITP"},"outputs":[],"source":["# examples = enumerate(validation_loader)\n","# batch_idx, (example_data, example_targets) = next(examples)"]},{"cell_type":"code","execution_count":null,"id":"lLUlkq993Y8c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":467,"status":"ok","timestamp":1698590248281,"user":{"displayName":"yf Wang","userId":"11168396825643978001"},"user_tz":-480},"id":"lLUlkq993Y8c","outputId":"61a63718-13db-4fed-eb6f-3d7b6b476840"},"outputs":[],"source":["# print(example_targets[-1])"]},{"cell_type":"code","execution_count":null,"id":"giERd_tuw_KV","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":560},"executionInfo":{"elapsed":1928,"status":"ok","timestamp":1698588346425,"user":{"displayName":"yf Wang","userId":"11168396825643978001"},"user_tz":-480},"id":"giERd_tuw_KV","outputId":"933427d4-4fc4-4f4f-f58e-4ef583b99e06"},"outputs":[],"source":["torch.save(model,'save.pt')\n","img_dir = \"/content/drive/My Drive\"\n","model=torch.load(os.path.join(img_dir,\"20cnn.pt\"), map_location='cpu')\n","\n","model.eval()\n","\n","\n","from pytorch_grad_cam import GradCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM\n","from pytorch_grad_cam.utils.image import show_cam_on_image, deprocess_image, preprocess_image\n","import matplotlib.pyplot as plt\n","\n","\n","import cv2\n","from google.colab.patches import cv2_imshow\n","from PIL import Image\n","im_tensor = example_data\n","im_tensor=im_tensor.reshape(len(example_data),1,64,60)\n","input_tensor = im_tensor[-1]\n","input_tensor = input_tensor.reshape(1,1,64,60)\n","\n","rgb_img = cv2.cvtColor(np.array(example_data[-1][0]).astype(np.uint8), cv2.COLOR_GRAY2BGR)\n","rgb_img = np.float32(rgb_img)\n","\n","\n","\n","target_layers = [[model.conv1],[model.conv2],[model.conv3]]\n","plt.figure(figsize=(8,8), dpi=80)\n","plt.figure(1)\n","\n","\n","img = np.array(example_data[-1][0]).astype(np.uint8)\n","example_data3=Image.fromarray(img).convert( \"L\" ) # numpy 转 image类\n","ax1 = plt.subplot(2,2,1)\n","ax1.imshow(example_data3)\n","plt.title(\"Original OHLC\")\n","for id, layer in enumerate(target_layers):\n","    cam = GradCAM(model=model, target_layers=layer)\n","    cam = cam(input_tensor=input_tensor, targets=None)\n","\n","    grayscale_cam = cam[0,:]\n","\n","    visualization = show_cam_on_image(np.array(rgb_img).astype(np.uint8) , grayscale_cam, use_rgb=False)\n","    ax1 = plt.subplot(2,2,id+2)\n","    ax1.imshow(visualization)\n","    plt.title(\"Layer {} OHLC\".format(id+1))\n","plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":5}
